import os
import aiohttp
import subprocess
import logging
import shutil
from telebot.async_telebot import AsyncTeleBot
from telebot.types import Message, ReplyKeyboardMarkup, KeyboardButton
from uuid import uuid4
from dotenv import load_dotenv
from config import LOG_DIR

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫
os.makedirs(LOG_DIR, exist_ok=True)
logging.basicConfig(filename=os.path.join(LOG_DIR, 'transcribe_errors.log'), level=logging.ERROR, format='%(asctime)s %(levelname)s %(message)s')

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '../../.env'))
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TEMP_DIR = "storage"
os.makedirs(TEMP_DIR, exist_ok=True)

from handlers.general import bot  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç –±–æ—Ç–∞

MAX_CHUNK_SIZE = 24 * 1024 * 1024  # 24 –ú–ë


def error_keyboard():
    markup = ReplyKeyboardMarkup(resize_keyboard=True)
    markup.add(KeyboardButton("–ü–æ–≤—Ç–æ—Ä–∏—Ç—å"))
    return markup

@bot.message_handler(func=lambda m: m.text == "–ü–æ–≤—Ç–æ—Ä–∏—Ç—å")
async def repeat_audio_instruction(message: Message):
    await bot.send_message(
        message.chat.id,
        "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —ç—Ç–æ—Ç —á–∞—Ç –µ—â—ë —Ä–∞–∑.",
        reply_markup=None
    )

@bot.message_handler(content_types=['voice', 'audio'])
async def transcribe_audio(message: Message):
    await bot.send_chat_action(message.chat.id, 'typing')
    await bot.send_message(message.chat.id, "‚è≥ –§–∞–π–ª –ø–æ–ª—É—á–µ–Ω, –Ω–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")

    file_id = message.voice.file_id if message.voice else message.audio.file_id
    ext = ".ogg" if message.voice else ".mp3"
    temp_file = os.path.join(TEMP_DIR, f"{uuid4()}{ext}")

    file_info = await bot.get_file(file_id)
    downloaded_file = await bot.download_file(file_info.file_path)
    with open(temp_file, "wb") as f:
        f.write(downloaded_file)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ mp3 –¥–ª—è Whisper
    temp_file_mp3 = temp_file.rsplit('.', 1)[0] + '.mp3'
    subprocess.run(["ffmpeg", "-y", "-i", temp_file, temp_file_mp3])

    file_size = os.path.getsize(temp_file_mp3)
    # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è (–ø—Ä–∏–º–µ—Ä–Ω–æ 1 –º–∏–Ω—É—Ç–∞ –Ω–∞ 5 –º–∏–Ω—É—Ç –∞—É–¥–∏–æ)
    approx_minutes = max(1, int(file_size / (1024 * 1024 * 2)))
    progress_msg = await bot.send_message(
        message.chat.id,
        f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞...\n–û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: ~{approx_minutes} –º–∏–Ω."
    )

    if file_size <= 25 * 1024 * 1024:
        try:
            await bot.edit_message_text(
                "üìù –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞...",
                chat_id=message.chat.id,
                message_id=progress_msg.message_id
            )
            transcription = await whisper_transcribe(temp_file_mp3)
            await send_long_message(bot, message.chat.id, f"üìù –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞:\n\n{transcription}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ –∞—É–¥–∏–æ: {e}")
            await bot.edit_message_text(
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ –∞—É–¥–∏–æ.\n\n{str(e)}",
                chat_id=message.chat.id,
                message_id=progress_msg.message_id,
                reply_markup=error_keyboard()
            )
            raise e
        finally:
            os.remove(temp_file)
            os.remove(temp_file_mp3)
        return

    # –ï—Å–ª–∏ —Ñ–∞–π–ª –±–æ–ª—å—à–æ–π ‚Äî —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø–∞—É–∑–∞–º —á–µ—Ä–µ–∑ ffmpeg
    await bot.edit_message_text(
        "üî™ –ù–∞—Ä–µ–∑–∫–∞ –∞—É–¥–∏–æ –ø–æ –ø–∞—É–∑–∞–º...",
        chat_id=message.chat.id,
        message_id=progress_msg.message_id
    )
    chunk_dir = os.path.join(TEMP_DIR, f"chunks_{uuid4()}")
    os.makedirs(chunk_dir, exist_ok=True)
    chunk_paths = split_audio_by_silence_ffmpeg(temp_file, chunk_dir)
    os.remove(temp_file)
    os.remove(temp_file_mp3)

    await bot.edit_message_text(
        f"üî™ –ù–∞—Ä–µ–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ö—É—Å–∫–æ–≤: {len(chunk_paths)}. –ù–∞—á–∏–Ω–∞—é —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É...",
        chat_id=message.chat.id,
        message_id=progress_msg.message_id
    )

    transcribed_text = ""
    for i, part_path in enumerate(chunk_paths):
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –∫—É—Å–æ–∫ –≤ mp3
        part_path_mp3 = part_path.rsplit('.', 1)[0] + '.mp3'
        subprocess.run(["ffmpeg", "-y", "-i", part_path, part_path_mp3])
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∫–∞–∂–¥–æ–≥–æ –∫—É—Å–∫–∞
        if os.path.getsize(part_path_mp3) > 25 * 1024 * 1024:
            await bot.send_message(message.chat.id, f"‚ùå –ö—É—Å–æ–∫ {i+1} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü—Ä–æ–ø—É—â–µ–Ω.")
            os.remove(part_path)
            os.remove(part_path_mp3)
            continue
        try:
            await bot.edit_message_text(
                f"üìù –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —á–∞—Å—Ç–∏ {i+1} –∏–∑ {len(chunk_paths)}...",
                chat_id=message.chat.id,
                message_id=progress_msg.message_id
            )
            part_text = await whisper_transcribe(part_path_mp3)
            transcribed_text += f"\n--- –ß–∞—Å—Ç—å {i+1} ---\n{part_text}\n"
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ —á–∞—Å—Ç–∏ {i+1}: {e}")
            await bot.send_message(
                message.chat.id,
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ —á–∞—Å—Ç–∏ {i+1}.\n\n{str(e)}",
                reply_markup=error_keyboard()
            )
            transcribed_text += f"\n--- –ß–∞—Å—Ç—å {i+1} ---\n–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ.\n"
        finally:
            os.remove(part_path)
            os.remove(part_path_mp3)
    shutil.rmtree(chunk_dir, ignore_errors=True)
    await bot.edit_message_text(
        "‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û—Ç–ø—Ä–∞–≤–ª—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç...",
        chat_id=message.chat.id,
        message_id=progress_msg.message_id
    )
    await send_long_message(bot, message.chat.id, f"üìù –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –ø–æ —á–∞—Å—Ç—è–º:\n{transcribed_text}")


def split_audio_by_silence_ffmpeg(input_path, output_dir, min_silence_len=0.7, silence_thresh=-30):
    """
    –ù–∞—Ä–µ–∑–∞–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ –ø–∞—É–∑–∞–º —Å –ø–æ–º–æ—â—å—é ffmpeg.
    min_silence_len ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–∏—à–∏–Ω—ã (—Å–µ–∫—É–Ω–¥—ã)
    silence_thresh ‚Äî —É—Ä–æ–≤–µ–Ω—å —Ç–∏—à–∏–Ω—ã –≤ dB (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ 0)
    """
    # 1. –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–∞
    duration = get_audio_duration(input_path)
    # 2. –ó–∞–ø—É—Å–∫–∞–µ–º ffmpeg –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–∞—É–∑
    command = [
        "ffmpeg", "-i", input_path,
        "-af", f"silencedetect=noise={silence_thresh}dB:d={min_silence_len}",
        "-f", "null", "-"
    ]
    result = subprocess.run(command, stderr=subprocess.PIPE, text=True)
    silence_starts = []
    silence_ends = []
    for line in result.stderr.splitlines():
        if "silence_start" in line:
            silence_starts.append(float(line.split("silence_start: ")[-1]))
        if "silence_end" in line:
            silence_ends.append(float(line.split("silence_end: ")[-1].split(" |") [0]))
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è –Ω–∞—Ä–µ–∑–∫–∏
    segments = []
    prev_end = 0.0
    for start in silence_starts:
        segments.append((prev_end, start))
        prev_end = start
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫—É—Å–æ–∫
    if prev_end < duration:
        segments.append((prev_end, duration))
    # –ù–∞—Ä–µ–∑–∞–µ–º –∞—É–¥–∏–æ
    chunk_paths = []
    for i, (start, end) in enumerate(segments):
        out_path = os.path.join(output_dir, f"chunk_{i+1}.ogg")
        subprocess.run([
            "ffmpeg", "-y", "-i", input_path,
            "-ss", str(start), "-to", str(end),
            "-c", "copy", out_path
        ])
        chunk_paths.append(out_path)
    return chunk_paths

def get_audio_duration(path):
    result = subprocess.run(
        ["ffprobe", "-v", "error", "-show_entries", "format=duration",
         "-of", "default=noprint_wrappers=1:nokey=1", path],
        stdout=subprocess.PIPE, text=True
    )
    return float(result.stdout.strip())


async def whisper_transcribe(audio_path: str) -> str:
    url = "https://api.openai.com/v1/audio/transcriptions"
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    
    async with aiohttp.ClientSession() as session:
        with open(audio_path, "rb") as f:
            form = aiohttp.FormData()
            form.add_field("file", f, filename=os.path.basename(audio_path))
            form.add_field("model", "whisper-1")
            async with session.post(url, data=form, headers=headers) as resp:
                resp.raise_for_status()
                response = await resp.json()
                return response["text"]

async def send_long_message(bot, chat_id, text, **kwargs):
    max_length = 4096
    for i in range(0, len(text), max_length):
        await bot.send_message(chat_id, text[i:i+max_length], **kwargs)
